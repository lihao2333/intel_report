\section{Fast-neural-style produce pictures}
\subsection{mainly principle}
The principle is shown in figure\ref{fig:fast-neural-style-principle}
\addfig[0.8]{fast-neural-style-principle.png}{fig:fast-neural-style-principle}{Principle of fast-nerual-style}
The entire network can be viewed as two parts, a graphical transformation network and a distorted network.

The graphical transformation network is a deep residual neural network, characterized by the parameter $W$. It converts the input image by mapping $\hat y=f_W(X)$ to the output image $\hat y$

Each distortion function measures the difference between the output image $\hat y$ and the target image $y$ by calculating $l_i(\hat y,y_i)$.

The graph transformation network is trained by the stochastic gradient descent method with the goal of minimizing total distortion.

The data set currently used is the COCO dataset, which contains a large number of generic images.

After training the model, the input image $x$ is propagated once through the front, and after the graphics transformation layer can get the output. So it's highly speed.
\subsection{Code structure}

\subsection{Call method}

\subsubsection{API}
The main API provided by fast-neural-sytle and the default values are as followed table \ref{tbl-abi-neural-style}
\addtbl{api-fastneuralstyle}
\subsubsection{django called fast-neural-style}
Such as\ref{fig:top}, When receiving the user's post request, firstly, the background obtains the content image and the style model information, and then stores the database and calls the fast-neural-style API. When the user requests the page to display, the background queries the database through the user id and outputs the result to presented.
The code that produces the image is as follows:
\addcode[python]{gen-image.py}
The tenth of these calls the fast-neural-style interface through system commands. The code is as follows:
\addcode[python]{func-fast-neural-style.py}
The code for viewing the picture is as follows
\addcode[python]{show-image.py}
